{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/angli/Documents/GitHub/ToxicCommentsClassification\n"
     ]
    }
   ],
   "source": [
    "cd /Users/angli/Documents/GitHub/ToxicCommentsClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAll_Wordcloud.py\u001b[m\u001b[m*\r\n",
      "CleanCommentGenerator.py\r\n",
      "Comment2VecPlot.py\r\n",
      "CommentsFeaturesGenerator.py\r\n",
      "DataExplorationPrediction_Features.ipynb\r\n",
      "DataExplorationPrediction_w2v.ipynb\r\n",
      "README.md\r\n",
      "ToxicCommentAnalysis.ipynb\r\n",
      "Word2Vec_merge.py\r\n",
      "Word2Vec_plot.py\r\n",
      "\u001b[1m\u001b[36mcabin-sketch-v1.02\u001b[m\u001b[m/\r\n",
      "\u001b[31mreport_update.docx\u001b[m\u001b[m*\r\n",
      "usingW2V.py\r\n",
      "w2v_train.py\r\n",
      "\u001b[1m\u001b[36mword_cloud_pngs\u001b[m\u001b[m/\r\n",
      "\u001b[31mwordcloud.pyc\u001b[m\u001b[m*\r\n",
      "x_tsne.csv\r\n",
      "x_tsne.png\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print (sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "sns.set(font_scale=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/angli/Ang/OneDrive/Documents/Pitt_PhD/Class/2018Spring/ML/finalProject/data/train_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = pd.read_csv(\"/Users/angli/Ang/OneDrive/Documents/Pitt_PhD/Class/2018Spring/ML/finalProject/data/c2wdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, w2v, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159491, 224)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'total_length', 'capitals', 'caps_vs_length',\n",
       "       'num_exclamation_marks', 'num_question_marks', 'num_punctuation',\n",
       "       'num_symbols', 'num_we', 'num_words', 'num_unique_words',\n",
       "       'words_vs_unique', 'num_smilies', 'num_IP', 'num_URL',\n",
       "       'num_positive', 'num_negtive', 'score', 'toxic', 'severe_toxic',\n",
       "       'obscene', 'threat', 'insult', 'identity_hate', '0', '1', '2', '3',\n",
       "       '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15',\n",
       "       '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26',\n",
       "       '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37',\n",
       "       '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n",
       "       '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59',\n",
       "       '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70',\n",
       "       '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81',\n",
       "       '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92',\n",
       "       '93', '94', '95', '96', '97', '98', '99', '100', '101', '102',\n",
       "       '103', '104', '105', '106', '107', '108', '109', '110', '111',\n",
       "       '112', '113', '114', '115', '116', '117', '118', '119', '120',\n",
       "       '121', '122', '123', '124', '125', '126', '127', '128', '129',\n",
       "       '130', '131', '132', '133', '134', '135', '136', '137', '138',\n",
       "       '139', '140', '141', '142', '143', '144', '145', '146', '147',\n",
       "       '148', '149', '150', '151', '152', '153', '154', '155', '156',\n",
       "       '157', '158', '159', '160', '161', '162', '163', '164', '165',\n",
       "       '166', '167', '168', '169', '170', '171', '172', '173', '174',\n",
       "       '175', '176', '177', '178', '179', '180', '181', '182', '183',\n",
       "       '184', '185', '186', '187', '188', '189', '190', '191', '192',\n",
       "       '193', '194', '195', '196', '197', '198', '199'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16225"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make the label as binary classification\n",
    "rowsums=train.iloc[:,18:24].sum(axis=1)\n",
    "#sum(list(rowsums>0))\n",
    "train['dirty']=(rowsums>0)\n",
    "train['dirty'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['dirty']\n",
    "x = train[['total_length', 'capitals', 'caps_vs_length',\n",
    "       'num_exclamation_marks', 'num_question_marks', 'num_punctuation',\n",
    "       'num_symbols', 'num_we', 'num_words', 'num_unique_words',\n",
    "       'words_vs_unique', 'num_smilies', 'num_IP', 'num_URL',\n",
    "       'num_positive', 'num_negtive', 'score', '0', '1', '2', '3',\n",
    "       '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15',\n",
    "       '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26',\n",
    "       '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37',\n",
    "       '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n",
    "       '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59',\n",
    "       '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70',\n",
    "       '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81',\n",
    "       '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92',\n",
    "       '93', '94', '95', '96', '97', '98', '99', '100', '101', '102',\n",
    "       '103', '104', '105', '106', '107', '108', '109', '110', '111',\n",
    "       '112', '113', '114', '115', '116', '117', '118', '119', '120',\n",
    "       '121', '122', '123', '124', '125', '126', '127', '128', '129',\n",
    "       '130', '131', '132', '133', '134', '135', '136', '137', '138',\n",
    "       '139', '140', '141', '142', '143', '144', '145', '146', '147',\n",
    "       '148', '149', '150', '151', '152', '153', '154', '155', '156',\n",
    "       '157', '158', '159', '160', '161', '162', '163', '164', '165',\n",
    "       '166', '167', '168', '169', '170', '171', '172', '173', '174',\n",
    "       '175', '176', '177', '178', '179', '180', '181', '182', '183',\n",
    "       '184', '185', '186', '187', '188', '189', '190', '191', '192',\n",
    "       '193', '194', '195', '196', '197', '198', '199']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train, test 7/3\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=42, \n",
    "                                                  test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10126922422364143"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.sum()/len(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 0.9331888250942737\n",
      "Training F1 score: 0.5347139916411952\n",
      "Testing Accuracy Rate: 0.9311987961879284\n",
      "Testing F1 score: 0.5237268518518519\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "model = LogisticRegression(penalty='l2')\n",
    "model.fit(xtrain,ytrain)\n",
    "\n",
    "prd_test = model.predict(xtest)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = model.predict(xtrain)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest,prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 0.9111901328341231\n",
      "Training F1 score: 0.6052160063706947\n",
      "Testing Accuracy Rate: 0.9103201805718107\n",
      "Testing F1 score: 0.6057877813504823\n"
     ]
    }
   ],
   "source": [
    "#naive bayes\n",
    "model = BernoulliNB()\n",
    "model.fit(xtrain,ytrain)\n",
    "\n",
    "prd_test = model.predict(xtest)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = model.predict(xtrain)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest,prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 0.986958429995611\n",
      "Training F1 score: 0.9346675042627659\n",
      "Testing Accuracy Rate: 0.9147508777796355\n",
      "Testing F1 score: 0.5801338136901698\n"
     ]
    }
   ],
   "source": [
    "#tree\n",
    "model = tree.DecisionTreeClassifier(criterion='gini', min_samples_split=5, min_samples_leaf=3)\n",
    "model.fit(xtrain,ytrain)\n",
    "\n",
    "prd_test = model.predict(xtest)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = model.predict(xtrain)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest,prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=50, n_jobs=5, oob_score=False,\n",
       "         random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bagging of decision tree -- entropy\n",
    "base = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "model = BaggingClassifier(base_estimator=base, n_estimators=50, random_state=1, n_jobs=5)\n",
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 0.9997312863323271\n",
      "Training F1 score: 0.9986715082809317\n",
      "Testing Accuracy Rate: 0.9485453937468651\n",
      "Testing F1 score: 0.6937810945273631\n"
     ]
    }
   ],
   "source": [
    "prd_test = model.predict(xtest)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = model.predict(xtrain)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest,prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=50, n_jobs=5, oob_score=False,\n",
       "         random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bagging of decision tree -- gini\n",
    "base = tree.DecisionTreeClassifier(criterion='gini')\n",
    "model = BaggingClassifier(base_estimator=base, n_estimators=50, random_state=1, n_jobs=5)\n",
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 0.9996417151097695\n",
      "Training F1 score: 0.9982278929647351\n",
      "Testing Accuracy Rate: 0.9467271359304464\n",
      "Testing F1 score: 0.6810959589640935\n"
     ]
    }
   ],
   "source": [
    "prd_test = model.predict(xtest)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = model.predict(xtrain)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest,prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adaboost of decision tree\n",
    "base = tree.DecisionTreeClassifier(criterion='gini')\n",
    "model = AdaBoostClassifier(base_estimator=base, n_estimators=50)\n",
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 1.0\n",
      "Training F1 score: 1.0\n",
      "Testing Accuracy Rate: 0.9096513960876108\n",
      "Testing F1 score: 0.570747691391123\n"
     ]
    }
   ],
   "source": [
    "prd_test = model.predict(xtest)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = model.predict(xtrain)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest,prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pre-process for nn, scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(xtrain)\n",
    "X_train = scaler.transform(xtrain)\n",
    "X_test = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelNN = MLPClassifier(hidden_layer_sizes=(100,100,100,100,100,100,100,100), activation = \"relu\", solver='lbfgs', alpha=0.0001, \n",
    "                    #learning_rate = 'constant', learning_rate_init = 0.001, \n",
    "                    max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 100, 100, 100, 100, 100, 100),\n",
       "       learning_rate='constant', learning_rate_init=0.001, max_iter=500,\n",
       "       momentum=0.9, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelNN.fit(X_train, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 0.9998208575548848\n",
      "Training F1 score: 0.9991155921110817\n",
      "Testing Accuracy Rate: 0.9439683999331215\n",
      "Testing F1 score: 0.7234086454142165\n"
     ]
    }
   ],
   "source": [
    "prd_test = modelNN.predict(X_test)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = modelNN.predict(X_train)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest, prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
