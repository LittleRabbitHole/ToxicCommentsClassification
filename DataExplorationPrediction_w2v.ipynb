{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Ang/Documents/GitHub/ToxicCommentsClassification\n"
     ]
    }
   ],
   "source": [
    "cd /Users/Ang/Documents/GitHub/ToxicCommentsClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAll_Wordcloud.py\u001b[m\u001b[m*\r\n",
      "CleanCommentGenerator.py\r\n",
      "Comment2VecPlot.py\r\n",
      "CommentsFeaturesGenerator.py\r\n",
      "DataExplorationPrediction_Features.ipynb\r\n",
      "DataExplorationPrediction_w2v.ipynb\r\n",
      "README.md\r\n",
      "ToxicCommentAnalysis.ipynb\r\n",
      "Word2Vec_merge.py\r\n",
      "Word2Vec_plot.py\r\n",
      "\u001b[1m\u001b[36mcabin-sketch-v1.02\u001b[m\u001b[m/\r\n",
      "\u001b[31mreport_update.docx\u001b[m\u001b[m*\r\n",
      "usingW2V.py\r\n",
      "w2v_train.py\r\n",
      "\u001b[1m\u001b[36mword_cloud_pngs\u001b[m\u001b[m/\r\n",
      "\u001b[31mwordcloud.pyc\u001b[m\u001b[m*\r\n",
      "x_tsne.csv\r\n",
      "x_tsne.png\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print (sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "sns.set(font_scale=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/Ang/OneDrive/Documents/Pitt_PhD/Class/2018Spring/ML/finalProject/data/train_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = pd.read_csv(\"/Users/Ang/OneDrive/Documents/Pitt_PhD/Class/2018Spring/ML/finalProject/data/c2wdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, w2v, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159491, 224)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'total_length', 'capitals', 'caps_vs_length',\n",
       "       'num_exclamation_marks', 'num_question_marks', 'num_punctuation',\n",
       "       'num_symbols', 'num_we', 'num_words', 'num_unique_words',\n",
       "       'words_vs_unique', 'num_smilies', 'num_IP', 'num_URL',\n",
       "       'num_positive', 'num_negtive', 'score', 'toxic', 'severe_toxic',\n",
       "       'obscene', 'threat', 'insult', 'identity_hate', '0', '1', '2', '3',\n",
       "       '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15',\n",
       "       '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26',\n",
       "       '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37',\n",
       "       '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n",
       "       '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59',\n",
       "       '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70',\n",
       "       '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81',\n",
       "       '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92',\n",
       "       '93', '94', '95', '96', '97', '98', '99', '100', '101', '102',\n",
       "       '103', '104', '105', '106', '107', '108', '109', '110', '111',\n",
       "       '112', '113', '114', '115', '116', '117', '118', '119', '120',\n",
       "       '121', '122', '123', '124', '125', '126', '127', '128', '129',\n",
       "       '130', '131', '132', '133', '134', '135', '136', '137', '138',\n",
       "       '139', '140', '141', '142', '143', '144', '145', '146', '147',\n",
       "       '148', '149', '150', '151', '152', '153', '154', '155', '156',\n",
       "       '157', '158', '159', '160', '161', '162', '163', '164', '165',\n",
       "       '166', '167', '168', '169', '170', '171', '172', '173', '174',\n",
       "       '175', '176', '177', '178', '179', '180', '181', '182', '183',\n",
       "       '184', '185', '186', '187', '188', '189', '190', '191', '192',\n",
       "       '193', '194', '195', '196', '197', '198', '199', 'dirty'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16225"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make the label as binary classification\n",
    "rowsums=train.iloc[:,18:24].sum(axis=1)\n",
    "#sum(list(rowsums>0))\n",
    "train['dirty']=(rowsums>0)\n",
    "train['dirty'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['dirty']\n",
    "x = train[['total_length', 'capitals', 'caps_vs_length',\n",
    "       'num_exclamation_marks', 'num_question_marks', 'num_punctuation',\n",
    "       'num_symbols', 'num_we', 'num_words', 'num_unique_words',\n",
    "       'words_vs_unique', 'num_smilies', 'num_IP', 'num_URL',\n",
    "       'num_positive', 'num_negtive', 'score', '0', '1', '2', '3',\n",
    "       '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15',\n",
    "       '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26',\n",
    "       '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37',\n",
    "       '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n",
    "       '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59',\n",
    "       '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70',\n",
    "       '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81',\n",
    "       '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92',\n",
    "       '93', '94', '95', '96', '97', '98', '99', '100', '101', '102',\n",
    "       '103', '104', '105', '106', '107', '108', '109', '110', '111',\n",
    "       '112', '113', '114', '115', '116', '117', '118', '119', '120',\n",
    "       '121', '122', '123', '124', '125', '126', '127', '128', '129',\n",
    "       '130', '131', '132', '133', '134', '135', '136', '137', '138',\n",
    "       '139', '140', '141', '142', '143', '144', '145', '146', '147',\n",
    "       '148', '149', '150', '151', '152', '153', '154', '155', '156',\n",
    "       '157', '158', '159', '160', '161', '162', '163', '164', '165',\n",
    "       '166', '167', '168', '169', '170', '171', '172', '173', '174',\n",
    "       '175', '176', '177', '178', '179', '180', '181', '182', '183',\n",
    "       '184', '185', '186', '187', '188', '189', '190', '191', '192',\n",
    "       '193', '194', '195', '196', '197', '198', '199']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test 7/3\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, random_state=42, \n",
    "                                                  test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10126922422364143"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.sum()/len(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 0.9331888250942737\n",
      "Training F1 score: 0.5347139916411952\n",
      "Testing Accuracy Rate: 0.9311987961879284\n",
      "Testing F1 score: 0.5237268518518519\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "model = LogisticRegression(penalty='l2')\n",
    "model.fit(xtrain,ytrain)\n",
    "\n",
    "prd_test = model.predict(xtest)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = model.predict(xtrain)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest,prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 0.9111901328341231\n",
      "Training F1 score: 0.6052160063706947\n",
      "Testing Accuracy Rate: 0.9103201805718107\n",
      "Testing F1 score: 0.6057877813504823\n"
     ]
    }
   ],
   "source": [
    "#naive bayes\n",
    "model = BernoulliNB()\n",
    "model.fit(xtrain,ytrain)\n",
    "\n",
    "prd_test = model.predict(xtest)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = model.predict(xtrain)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest,prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 0.986958429995611\n",
      "Training F1 score: 0.9346675042627659\n",
      "Testing Accuracy Rate: 0.9147508777796355\n",
      "Testing F1 score: 0.5801338136901698\n"
     ]
    }
   ],
   "source": [
    "#tree\n",
    "model = tree.DecisionTreeClassifier(criterion='gini', min_samples_split=5, min_samples_leaf=3)\n",
    "model.fit(xtrain,ytrain)\n",
    "\n",
    "prd_test = model.predict(xtest)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = model.predict(xtrain)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest,prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=20, n_jobs=5, oob_score=False,\n",
       "         random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bagging of decision tree -- entropy\n",
    "base = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "model = BaggingClassifier(base_estimator=base, n_estimators=20, random_state=1, n_jobs=5)\n",
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 0.9979309047589191\n",
      "Training F1 score: 0.9896805896805897\n",
      "Testing Accuracy Rate: 0.9466853369001839\n",
      "Testing F1 score: 0.6821975831568456\n"
     ]
    }
   ],
   "source": [
    "prd_test = model.predict(xtest)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = model.predict(xtrain)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest,prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=20, n_jobs=5, oob_score=False,\n",
       "         random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bagging of decision tree -- gini\n",
    "base = tree.DecisionTreeClassifier(criterion='gini')\n",
    "model = BaggingClassifier(base_estimator=base, n_estimators=20, random_state=1, n_jobs=5)\n",
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 0.9976980195802693\n",
      "Training F1 score: 0.9885067751889449\n",
      "Testing Accuracy Rate: 0.9451178732653402\n",
      "Testing F1 score: 0.6714214214214215\n"
     ]
    }
   ],
   "source": [
    "prd_test = model.predict(xtest)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = model.predict(xtrain)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest,prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adaboost of decision tree\n",
    "base = tree.DecisionTreeClassifier(criterion='gini')\n",
    "model = AdaBoostClassifier(base_estimator=base, n_estimators=10)\n",
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Rate: 1.0\n",
      "Training F1 score: 1.0\n",
      "Testing Accuracy Rate: 0.909588697542217\n",
      "Testing F1 score: 0.5698090692124105\n"
     ]
    }
   ],
   "source": [
    "prd_test = model.predict(xtest)\n",
    "#prd_test_label = prd_test.astype(int)\n",
    "    \n",
    "prd_train = model.predict(xtrain)\n",
    "#prd_train_label = prd_train.astype(int)\n",
    "    \n",
    "train_accuracy = accuracy_score(ytrain, prd_train)\n",
    "train_f1 = f1_score(ytrain, prd_train)\n",
    "test_accuracy = accuracy_score(ytest,prd_test)\n",
    "test_f1 = f1_score(ytest,prd_test)\n",
    "    \n",
    "print('Training Accuracy Rate:', train_accuracy)\n",
    "print('Training F1 score:', train_f1)\n",
    "print('Testing Accuracy Rate:', test_accuracy)\n",
    "print('Testing F1 score:', test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://scikit-learn.org/stable/modules/neural_networks_supervised.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
